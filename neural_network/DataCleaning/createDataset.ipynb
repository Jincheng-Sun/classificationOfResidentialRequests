{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gd5BPdPIqmA8",
    "colab_type": "text"
   },
   "source": [
    "**Copy the folder to your google drive, using the code below to mount your google drive.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-gORbyoYb6wF",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    },
    "outputId": "3c8cde5a-4160-41d5-a036-6699973c571e",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.556826694463E12,
     "user_tz": 240.0,
     "elapsed": 2456.0,
     "user": {
      "displayName": "J S",
      "photoUrl": "",
      "userId": "13072661957226620589"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/My Drive\n",
      "'API Document.gdoc'  'Deep Learning'   new_assessment\t    Template\n",
      " Autoencoder.ipynb    GAN\t       NLP_classification   Training\n",
      "'Colab Notebooks'     models\t       Res40000_157\t    Untitled\n",
      " data\t\t      myToolKit        Res40000_5\t    无标题文档.gdoc\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/My\\ Drive\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "tIuooLOZYZ-A",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import jieba\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D2Vy0zMZi1x",
    "colab_type": "text"
   },
   "source": [
    "**Data path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "Wkzf6b5BZh5v",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "data_path = 'NLP_classification/data/all_valid_data.csv'\n",
    "labels_path = 'NLP_classification/data/all_labels.txt'\n",
    "stop_words = 'NLP_classification/data/baidu+chuanda.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Xg-N83YbT28",
    "colab_type": "text"
   },
   "source": [
    "**Load the label dictionary and the stopword list**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "mh561r-DZgom",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "file = open(labels_path,'r', encoding='gb18030')\n",
    "for line in file:\n",
    "    labels[line.split(',')[0]] = int(line.split(',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "I28UTdu8cYw4",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "stopwords = [line[0:-1] for line in open(stop_words, 'r', encoding='utf-8').readlines()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0QYCDpsfcAc",
    "colab_type": "text"
   },
   "source": [
    "**split data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "mHR2ChIhem6l",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(data_path, encoding = 'gb18030')\n",
    "dataset = dataset.rename(columns={'诉求内容':'Description', '处置单位':'Department'})\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "'''extract 20% of the dataset as the testset. Using random state of 42'''\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset['Description'], dataset['Department'], test_size=0.2, random_state=42)\n",
    "\n",
    "'''due to the limit of memory, we take 40,000 data samples first from the trainset'''\n",
    "\n",
    "_, x_40000, _, y_40000 = train_test_split(x_train, y_train, test_size = 40000, random_state=24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wQHSj2uPDcTZ",
    "colab_type": "text"
   },
   "source": [
    "**Load Word2Vec model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "GVRWnTuBsHtU",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec.load('NLP_classification/models/CBOW.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TkVhssUE-nk",
    "colab_type": "text"
   },
   "source": [
    "**Take the first 100 words of a description, convert them to 100*100 features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "RkIOTJlswGRH",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "def map1(data):\n",
    "  data = re.sub('市民来电咨询', '', data)\n",
    "  data = re.sub('市民来电反映', '', data)\n",
    "  data = re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[a-zA-Z0-9+——！，。？、~@#￥%……&*（）《》：:]+\", \"\", data)\n",
    "  words = jieba.cut(data)\n",
    "  vector = np.array([])\n",
    "  for word in words:\n",
    "\n",
    "    if word in stopwords:\n",
    "        continue\n",
    "    try:\n",
    "        vec = w2v_model[word]\n",
    "        vector = np.append(vector, vec)\n",
    "        if (vector.shape[0] == 10000):\n",
    "            break\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "  if (vector.shape[0] < 10000):\n",
    "      pendding = np.zeros(10000 - vector.shape[0])\n",
    "      vector = np.append(vector, pendding)\n",
    "  return vector.reshape([100,100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZfSZOflUGmj3",
    "colab_type": "text"
   },
   "source": [
    "**This step will take about 2 mins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UZJrex_zwJqX",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139.0
    },
    "outputId": "82ad4130-de3b-490f-c384-e2786ff1c512",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.556826765085E12,
     "user_tz": 240.0,
     "elapsed": 73039.0,
     "user": {
      "displayName": "J S",
      "photoUrl": "",
      "userId": "13072661957226620589"
     }
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /tmp/jieba.cache\n",
      "Loading model cost 0.695 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "x_40000 = x_40000.map(map1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "SNwSdQ1gyjQ_",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    },
    "outputId": "ba990a19-a6bf-4331-ee23-ddbac039b2bd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.556826765086E12,
     "user_tz": 240.0,
     "elapsed": 73034.0,
     "user": {
      "displayName": "J S",
      "photoUrl": "",
      "userId": "13072661957226620589"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346879    [[-3.03849458694458, -5.231710910797119, 1.353...\n",
       "451239    [[1.030799388885498, -3.083348035812378, 1.234...\n",
       "360550    [[-1.8268845081329346, 1.4179006814956665, -3....\n",
       "296853    [[-2.067160129547119, -1.3425666093826294, 0.9...\n",
       "530001    [[-0.3960898518562317, 0.5878874659538269, -5....\n",
       "Name: Description, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_40000.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Umz8aU54Fs6X",
    "colab_type": "text"
   },
   "source": [
    "**Convert department name to a numerical label, can also use 'pd.get_dummies' instead**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "id": "YpHojFn12YqN",
    "colab_type": "code",
    "colab": {}
   },
   "outputs": [],
   "source": [
    "y_40000 = y_40000.map(lambda x:labels[x])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Ei26Yh0X2bmG",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119.0
    },
    "outputId": "370ae1f9-9f6a-42b5-ad86-566d9d8e69d2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1.556826765091E12,
     "user_tz": 240.0,
     "elapsed": 73018.0,
     "user": {
      "displayName": "J S",
      "photoUrl": "",
      "userId": "13072661957226620589"
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "346879    113\n",
       "451239     71\n",
       "360550     53\n",
       "296853     21\n",
       "530001      8\n",
       "Name: Department, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_40000.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "createDataset.ipynb",
   "version": "0.3.2",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
